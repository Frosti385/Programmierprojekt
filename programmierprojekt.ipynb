{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMWY/E681vFVWQOaMfGXt4G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Frosti385/Programmierprojekt/blob/developLarsTwo/programmierprojekt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XJHLA1k9k6U"
      },
      "outputs": [],
      "source": [
        "# Google Drive mounten und die Dateien als Cache reinladen (Bessere Laufzeit)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!mkdir \"/content/drive2/\"\n",
        "%cp -av \"/content/drive/MyDrive/data\" \"/content/drive2/\"\n",
        "%cp -av \"/content/drive/MyDrive/garbage_files/\" \"/content/drive2/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Netz trainieren VGG16\n",
        "\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def load_data(path: str):\n",
        "    with open(path, \"r\") as f:\n",
        "        files = f.readlines()\n",
        "        targets = []\n",
        "        images = []\n",
        "\n",
        "        for line in files:\n",
        "            name, target = line.split(\" \")\n",
        "            if name.startswith(\"paper\"):\n",
        "                path = f\"/content/drive2/data/paper/{name}\"\n",
        "            elif name.startswith(\"glass\"):\n",
        "                path = f\"/content/drive2/data/glass/{name}\"\n",
        "            elif name.startswith(\"metal\"):\n",
        "                path = f\"/content/drive2/data/metal/{name}\"\n",
        "            elif name.startswith(\"cardboard\"):\n",
        "                path = f\"/content/drive2/data/cardboard/{name}\"\n",
        "            elif name.startswith(\"plastic\"):\n",
        "                path = f\"/content/drive2/data/plastic/{name}\"\n",
        "            elif name.startswith(\"trash\"):\n",
        "                path = f\"/content/drive2/data/trash/{name}\"\n",
        "\n",
        "            targets.append(int(target)-1)\n",
        "            image = torchvision.io.read_image(path)\n",
        "            images.append(image)\n",
        "\n",
        "    return images, targets\n",
        "\n",
        "\n",
        "class TrashDataset(Dataset):\n",
        "\n",
        "  def __init__(self, images, targets):\n",
        "    self.targets = targets\n",
        "    self.images = images\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.targets)\n",
        "\n",
        "  transform = transforms.Compose(\n",
        "    [transforms.ToPILImage(),\n",
        "     transforms.Resize((224, 224)),\n",
        "     transforms.ToTensor()])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.targets[index], self.transform(self.images[index])\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.network = torchvision.models.vgg16(pretrained=True)\n",
        "    self.fc1 = nn.Linear(1000, 6)\n",
        "  def forward(self, x):\n",
        "    x = self.network(x)\n",
        "    x = self.fc1(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "batch_size = 40\n",
        "cv_scores = []\n",
        "\n",
        "train_images, train_targets = load_data(\"/content/drive/MyDrive/garbage_files/one-indexed-files-notrash_train.txt\")\n",
        "train_dataset = TrashDataset(images=train_images, targets=train_targets)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "cv_images, cv_targets = load_data(\"/content/drive/MyDrive/garbage_files/one-indexed-files-notrash_val.txt\")\n",
        "cv_dataset = TrashDataset(images=cv_images, targets=cv_targets)\n",
        "cv_loader = torch.utils.data.DataLoader(cv_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "\n",
        "net = Net()\n",
        "net.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_ft = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\n",
        "for epoch in range(20):\n",
        "    for idx, data in enumerate(train_loader):\n",
        "        targets, inputs = data\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "          targets, inputs = targets.cuda(), inputs.cuda()\n",
        "\n",
        "        optimizer_ft.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer_ft.step()\n",
        "        print(f'[{epoch + 1}, {idx + 1:5d}] loss: {loss}')\n",
        "\n",
        "        correct = 0\n",
        "        total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in cv_loader:\n",
        "            targets, inputs = data\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "              targets, inputs = targets.cuda(), inputs.cuda()\n",
        "            outputs = net(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "        print(f'Accuracy of the network on the cv images: {100 * correct // total} %')\n",
        "        \n",
        "        torch.save(net, \"/content/drive/MyDrive/models/epoch.max\")\n",
        "\n",
        "        cv_scores.append(100 * correct // total)\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "print('Finished Training')\n",
        "print(cv_scores)\n"
      ],
      "metadata": {
        "id": "9oSNjJGf9p0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Netz trainieren Resnet\n",
        "\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def load_data(path: str):\n",
        "    with open(path, \"r\") as f:\n",
        "        files = f.readlines()\n",
        "        targets = []\n",
        "        images = []\n",
        "\n",
        "        for line in files:\n",
        "            name, target = line.split(\" \")\n",
        "            if name.startswith(\"paper\"):\n",
        "                path = f\"/content/drive2/data/paper/{name}\"\n",
        "            elif name.startswith(\"glass\"):\n",
        "                path = f\"/content/drive2/data/glass/{name}\"\n",
        "            elif name.startswith(\"metal\"):\n",
        "                path = f\"/content/drive2/data/metal/{name}\"\n",
        "            elif name.startswith(\"cardboard\"):\n",
        "                path = f\"/content/drive2/data/cardboard/{name}\"\n",
        "            elif name.startswith(\"plastic\"):\n",
        "                path = f\"/content/drive2/data/plastic/{name}\"\n",
        "            elif name.startswith(\"trash\"):\n",
        "                path = f\"/content/drive2/data/trash/{name}\"\n",
        "\n",
        "            targets.append(int(target)-1)\n",
        "            image = torchvision.io.read_image(path)\n",
        "            images.append(image)\n",
        "\n",
        "    return images, targets\n",
        "\n",
        "\n",
        "class TrashDataset(Dataset):\n",
        "\n",
        "  def __init__(self, images, targets):\n",
        "    self.targets = targets\n",
        "    self.images = images\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.targets)\n",
        "\n",
        "  transform = transforms.Compose(\n",
        "    [transforms.ToPILImage(),\n",
        "     transforms.Resize((224, 224)),\n",
        "     transforms.ToTensor()])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.targets[index], self.transform(self.images[index])\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.network = torchvision.models.resnet152(pretrained=True)\n",
        "    self.fc1 = nn.Linear(1000, 6)\n",
        "  def forward(self, x):\n",
        "    x = self.network(x)\n",
        "    x = self.fc1(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "batch_size = 40\n",
        "cv_scores = []\n",
        "\n",
        "train_images, train_targets = load_data(\"/content/drive/MyDrive/garbage_files/one-indexed-files-notrash_train.txt\")\n",
        "train_dataset = TrashDataset(images=train_images, targets=train_targets)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "cv_images, cv_targets = load_data(\"/content/drive/MyDrive/garbage_files/one-indexed-files-notrash_val.txt\")\n",
        "cv_dataset = TrashDataset(images=cv_images, targets=cv_targets)\n",
        "cv_loader = torch.utils.data.DataLoader(cv_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "\n",
        "net = Net()\n",
        "net.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_ft = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\n",
        "for epoch in range(20):\n",
        "    for idx, data in enumerate(train_loader):\n",
        "        targets, inputs = data\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "          targets, inputs = targets.cuda(), inputs.cuda()\n",
        "\n",
        "        optimizer_ft.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer_ft.step()\n",
        "        print(f'[{epoch + 1}, {idx + 1:5d}] loss: {loss}')\n",
        "\n",
        "        correct = 0\n",
        "        total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in cv_loader:\n",
        "            targets, inputs = data\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "              targets, inputs = targets.cuda(), inputs.cuda()\n",
        "            outputs = net(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "        print(f'Accuracy of the network on the cv images: {100 * correct // total} %')\n",
        "        \n",
        "        torch.save(net, \"/content/drive/MyDrive/models/epoch.max\")\n",
        "\n",
        "        cv_scores.append(100 * correct // total)\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "print('Finished Training')\n",
        "print(cv_scores)"
      ],
      "metadata": {
        "id": "72-InQ729rYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Packages Laden, Funktionieren Definieren, Klassen erstellen - falls nur die Testdaten ausgeführt werden sollen\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def load_data(path: str):\n",
        "    with open(path, \"r\") as f:\n",
        "        files = f.readlines()\n",
        "        targets = []\n",
        "        images = []\n",
        "\n",
        "        for line in files:\n",
        "            name, target = line.split(\" \")\n",
        "            if name.startswith(\"paper\"):\n",
        "                path = f\"/content/drive2/data/paper/{name}\"\n",
        "            elif name.startswith(\"glass\"):\n",
        "                path = f\"/content/drive2/data/glass/{name}\"\n",
        "            elif name.startswith(\"metal\"):\n",
        "                path = f\"/content/drive2/data/metal/{name}\"\n",
        "            elif name.startswith(\"cardboard\"):\n",
        "                path = f\"/content/drive2/data/cardboard/{name}\"\n",
        "            elif name.startswith(\"plastic\"):\n",
        "                path = f\"/content/drive2/data/plastic/{name}\"\n",
        "            elif name.startswith(\"trash\"):\n",
        "                path = f\"/content/drive2/data/trash/{name}\"\n",
        "\n",
        "            targets.append(int(target)-1)\n",
        "            image = torchvision.io.read_image(path)\n",
        "            images.append(image)\n",
        "\n",
        "    return images, targets\n",
        "\n",
        "\n",
        "\n",
        "class TrashDataset(Dataset):\n",
        "\n",
        "  def __init__(self, images, targets):\n",
        "    self.targets = targets\n",
        "    self.images = images\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.targets)\n",
        "\n",
        "  transform = transforms.Compose(\n",
        "    [transforms.ToPILImage(),\n",
        "     transforms.Resize((224, 224)),\n",
        "     transforms.ToTensor()])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.targets[index], self.transform(self.images[index])\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.network = torchvision.models.resnet152(pretrained=True)\n",
        "    self.fc1 = nn.Linear(1000, 6)\n",
        "  def forward(self, x):\n",
        "    x = self.network(x)\n",
        "    x = self.fc1(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "-WqLrByR9tE7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testdaten laden und Netz evaluieren\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "classes = ['Glas', 'Papier', 'Pappe', 'Plastik', 'Metall', 'Müll']\n",
        "batch_size = 40\n",
        "\n",
        "net = Net()\n",
        "net.to(device)\n",
        "\n",
        "model = torch.load(\"/content/drive/MyDrive/models/epoch.max\", map_location=torch.device(device))\n",
        "try_image, try_target = load_data(\"/content/drive/MyDrive/garbage_files/one-indexed-files-notrash_test.txt\")\n",
        "try_dataset = TrashDataset(images=try_image, targets=try_target)\n",
        "try_loader = torch.utils.data.DataLoader(try_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "\"\"\"\n",
        "for data in try_loader:\n",
        "  targets, inputs = data\n",
        "  #targets, inputs = targets.cuda(), inputs.cuda()\n",
        "  outputs = net(inputs)\n",
        "  _, predicted = torch.max(outputs.data,1)\n",
        "  print(f\"Der Müll auf dem Bild ist {classes[predicted]}\")\n",
        "\"\"\"\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in try_loader:\n",
        "    targets, inputs = data\n",
        "    if torch.cuda.is_available():\n",
        "      targets, inputs = targets.cuda(), inputs.cuda()\n",
        "    outputs = model(inputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += targets.size(0)\n",
        "    correct += (predicted == targets).sum().item()\n",
        "  print(f'Accuracy of the network on the test images: {100 * correct // total} %')\n",
        "        \n",
        "\n"
      ],
      "metadata": {
        "id": "jVAr2sNn9urP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}