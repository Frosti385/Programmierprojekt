{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkSGRMZ3lcQn"
      },
      "outputs": [],
      "source": [
        "pip install cuda-python torch torchvision torchaudio Cython --extra-index-url https://download.pytorch.org/whl/cu116"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJL-lkmD9bYZ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!mkdir \"/content/drive2/\"\n",
        "%cp -av \"/content/drive/MyDrive/data\" \"/content/drive2/\"\n",
        "%cp -av \"/content/drive/MyDrive/garbage_files/\" \"/content/drive2/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DfnGzAVfBxRU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "import numpy as np\n",
        "\n",
        "def load_data(path: str):\n",
        "    with open(path, \"r\") as f:\n",
        "        files = f.readlines()\n",
        "        targets = []\n",
        "        images = []\n",
        "\n",
        "        for line in files:\n",
        "            name, target = line.split(\" \")\n",
        "            if name.startswith(\"paper\"):\n",
        "                path = f\"/content/drive2/data/paper/{name}\"\n",
        "            elif name.startswith(\"glass\"):\n",
        "                path = f\"/content/drive2/data/glass/{name}\"\n",
        "            elif name.startswith(\"metal\"):\n",
        "                path = f\"/content/drive2/data/metal/{name}\"\n",
        "            elif name.startswith(\"cardboard\"):\n",
        "                path = f\"/content/drive2/data/cardboard/{name}\"\n",
        "            elif name.startswith(\"plastic\"):\n",
        "                path = f\"/content/drive2/data/plastic/{name}\"\n",
        "            elif name.startswith(\"trash\"):\n",
        "                path = f\"/content/drive2/data/trash/{name}\"\n",
        "\n",
        "            targets.append(int(target)-1)\n",
        "            image = torchvision.io.read_image(path)\n",
        "            images.append(image)\n",
        "\n",
        "    return images, targets\n",
        "\n",
        "\n",
        "\n",
        "class TrashDataset(Dataset):\n",
        "\n",
        "  def __init__(self, images, targets):\n",
        "    self.targets = targets\n",
        "    self.images = images\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.targets)\n",
        "\n",
        "  transform = transforms.Compose(\n",
        "    [transforms.ToPILImage(),\n",
        "     transforms.Resize((224, 224)),\n",
        "     transforms.ToTensor()])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.targets[index], self.transform(self.images[index])\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.network = torchvision.models.vgg19(pretrained=True)\n",
        "    self.fc1 = nn.Linear(1000, 6)\n",
        "  def forward(self, x):\n",
        "    x = self.network(x)\n",
        "    x = self.fc1(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpZyyUXp0kCU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def load_data(path: str):\n",
        "    with open(path, \"r\") as f:\n",
        "        files = f.readlines()\n",
        "        targets = []\n",
        "        images = []\n",
        "\n",
        "        for line in files:\n",
        "            name, target = line.split(\" \")\n",
        "            if name.startswith(\"paper\"):\n",
        "                path = f\"/content/drive2/data/paper/{name}\"\n",
        "            elif name.startswith(\"glass\"):\n",
        "                path = f\"/content/drive2/data/glass/{name}\"\n",
        "            elif name.startswith(\"metal\"):\n",
        "                path = f\"/content/drive2/data/metal/{name}\"\n",
        "            elif name.startswith(\"cardboard\"):\n",
        "                path = f\"/content/drive2/data/cardboard/{name}\"\n",
        "            elif name.startswith(\"plastic\"):\n",
        "                path = f\"/content/drive2/data/plastic/{name}\"\n",
        "            elif name.startswith(\"trash\"):\n",
        "                path = f\"/content/drive2/data/trash/{name}\"\n",
        "\n",
        "            targets.append(int(target)-1)\n",
        "            image = torchvision.io.read_image(path)\n",
        "            images.append(image)\n",
        "\n",
        "    return images, targets\n",
        "\n",
        "\n",
        "class TrashDataset(Dataset):\n",
        "\n",
        "  def __init__(self, images, targets):\n",
        "    self.targets = targets\n",
        "    self.images = images\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.targets)\n",
        "\n",
        "  transform = transforms.Compose(\n",
        "    [transforms.ToPILImage(),\n",
        "     transforms.Resize((224, 224)),\n",
        "     transforms.ToTensor()])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.targets[index], self.transform(self.images[index])\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.network = torchvision.models.resnet152(pretrained=True)\n",
        "    self.fc1 = nn.Linear(1000, 6)\n",
        "  def forward(self, x):\n",
        "    x = self.network(x)\n",
        "    x = self.fc1(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "batch_size = 40\n",
        "cv_scores = [0]\n",
        "\n",
        "train_images, train_targets = load_data(\"/content/drive/MyDrive/garbage_files/one-indexed-files-notrash_train.txt\")\n",
        "train_dataset = TrashDataset(images=train_images, targets=train_targets)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "cv_images, cv_targets = load_data(\"/content/drive/MyDrive/garbage_files/one-indexed-files-notrash_val.txt\")\n",
        "cv_dataset = TrashDataset(images=cv_images, targets=cv_targets)\n",
        "cv_loader = torch.utils.data.DataLoader(cv_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "\n",
        "net = Net()\n",
        "net.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_ft = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\n",
        "for epoch in range(1):\n",
        "    for idx, data in enumerate(train_loader):\n",
        "        targets, inputs = data\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "          targets, inputs = targets.cuda(), inputs.cuda()\n",
        "\n",
        "        optimizer_ft.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer_ft.step()\n",
        "        print(f'[{epoch + 1}, {idx + 1:5d}] loss: {loss}')\n",
        "\n",
        "        correct = 0\n",
        "        total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in cv_loader:\n",
        "            targets, inputs = data\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "              targets, inputs = targets.cuda(), inputs.cuda()\n",
        "            outputs = net(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "        cv_score = 100 * correct // total\n",
        "        print(f'Accuracy of the network on the cv images: {100 * correct // total} %')\n",
        "        \n",
        "        if cv_score > max(cv_scores):    \n",
        "          torch.save(net, f\"/content/drive/MyDrive/models/epoch.max\")\n",
        "\n",
        "        cv_scores.append(100 * correct // total)\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "print('Finished Training')\n",
        "print(cv_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "nQKo_OEk0tcM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c7d9ee3-9e8a-4123-abb4-9c34ccbed2f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on all test images: 95 %\n",
            "Accuracy of the network on glass images: 95 %\n",
            "Accuracy of the network on paper images: 95 %\n",
            "Accuracy of the network on cardboard images: 97 %\n",
            "Accuracy of the network on plastic images: 95 %\n",
            "Accuracy of the network on metal images: 95 %\n",
            "Accuracy of the network on trash images: 89 %\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "classes = ['Glas', 'Papier', 'Pappe', 'Plastik', 'Metall', 'Müll']\n",
        "batch_size = 64\n",
        "net = Net()\n",
        "net.to(device)\n",
        "\n",
        "model = torch.load(\"/content/drive/MyDrive/models/epoch.max\")\n",
        "try_image, try_target = load_data(\"/content/drive/MyDrive/garbage_files/one-indexed-files-notrash_test.txt\")\n",
        "try_dataset = TrashDataset(images=try_image, targets=try_target)\n",
        "try_loader = torch.utils.data.DataLoader(try_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "types = [[0,0,0,0,0,0],[0,0,0,0,0,0]]\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in try_loader:\n",
        "    targets, inputs = data\n",
        "    targets, inputs = targets.cuda(), inputs.cuda()\n",
        "    # calculate outputs by running images through the network\n",
        "    outputs = model(inputs)\n",
        "    # the class with the highest energy is what we choose as prediction\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    for i in range(0, int(predicted.shape[0] - 1)):\n",
        "      types[0][predicted[i]] = types[0][predicted[i]] + 1\n",
        "      types[1][predicted[i]] = types[1][predicted[i]] + int(predicted[i] == targets[i])\n",
        "    total += targets.size(0)\n",
        "    correct += (predicted == targets).sum().item()\n",
        "  print(f'Accuracy of the network on all test images: {100 * correct // total} %')\n",
        "  print(f'Accuracy of the network on glass images: {100 * types[1][0] // types[0][0]} %')\n",
        "  print(f'Accuracy of the network on paper images: {100 * types[1][1] // types[0][1]} %')\n",
        "  print(f'Accuracy of the network on cardboard images: {100 * types[1][2] // types[0][2]} %')\n",
        "  print(f'Accuracy of the network on plastic images: {100 * types[1][3] // types[0][3]} %')\n",
        "  print(f'Accuracy of the network on metal images: {100 * types[1][4] // types[0][4]} %')\n",
        "  print(f'Accuracy of the network on trash images: {100 * types[1][5] // types[0][5]} %')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import walk\n",
        "import os\n",
        "import json\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "out = [\"\",\"\",\"\",\"\",\"\",\"\"]\n",
        "classes = ['Glas', 'Papier', 'Pappe', 'Plastik', 'Metall', 'Muell']\n",
        "batch_size = 64\n",
        "net = Net()\n",
        "net.to(device)\n",
        "\n",
        "model = torch.load(\"/content/drive/MyDrive/models/epoch.max\")\n",
        "pathToPic = \"/content/drive/MyDrive/einzuordnendesFoto/\"\n",
        "testPic = \"/content/drive/MyDrive/einzuordnendesFoto/test.jpg\"\n",
        "\n",
        "filename = (pathToPic +(\"\".join(next(walk(pathToPic), (None, None, []))[2])).replace(\"['\", \"\").replace(\"']\", \"\"))\n",
        "os.rename(filename, testPic)\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToPILImage(),\n",
        "     transforms.Resize((224, 224)),\n",
        "     transforms.ToTensor()])\n",
        "\n",
        "try_image = transform(torchvision.io.read_image(testPic))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  inputs = try_image\n",
        "  inputs = inputs.cuda()\n",
        "  inputs = inputs.unsqueeze(0)\n",
        "  outputs = model(inputs)\n",
        "  probability = torch.softmax(outputs.data, 1).cpu().numpy()[0]\n",
        "  maximum = 0\n",
        "  for u in range(0,6):\n",
        "    for i in range(0,6):\n",
        "      if (probability[i] == max(probability)) :\n",
        "        maximum = i;\n",
        "        break\n",
        "    #print(\"Müll auf dem Bild entspricht zu \" + \"{0:.10f}\".format(float(probability[maximum]*100)) + \"% dem Typ \" + classes[maximum])\n",
        "    out[i] = (\"Muell auf dem Bild entspricht zu \" + \"{0:.10f}\".format(float(probability[maximum]*100)) + \"% dem Typ \" + classes[maximum])\n",
        "    probability[maximum] = 0\n",
        "  js = {\n",
        "    \"0\" : out[0],\n",
        "    \"1\" : out[1],\n",
        "    \"2\" : out[2],\n",
        "    \"3\" : out[3],\n",
        "    \"4\" : out[4],\n",
        "    \"5\" : out[5]\n",
        "  }\n",
        "  js = json.dumps(js)\n",
        "  file = open(\"/content/drive/MyDrive/Output.json\", \"w\")\n",
        "  file.write(js)\n",
        "  file.close()"
      ],
      "metadata": {
        "id": "32LyqEDR27do"
      },
      "execution_count": 65,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}